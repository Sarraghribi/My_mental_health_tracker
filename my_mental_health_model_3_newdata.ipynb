{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9549501-644f-4316-9f11-2a49cbae61f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.7.0.72-cp37-abi3-win_amd64.whl (38.2 MB)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\sarra\\anaconda3\\envs\\tf\\lib\\site-packages (from opencv-python) (1.24.3)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.7.0.72\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e56006ce-fd8a-4c15-b6d9-316451956e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pillow\n",
      "  Downloading Pillow-9.5.0-cp310-cp310-win_amd64.whl (2.5 MB)\n",
      "                                              0.0/2.5 MB ? eta -:--:--\n",
      "     --                                       0.1/2.5 MB 8.3 MB/s eta 0:00:01\n",
      "     ------                                   0.4/2.5 MB 6.3 MB/s eta 0:00:01\n",
      "     ----------                               0.6/2.5 MB 5.8 MB/s eta 0:00:01\n",
      "     --------------                           0.9/2.5 MB 5.6 MB/s eta 0:00:01\n",
      "     -----------------                        1.1/2.5 MB 5.1 MB/s eta 0:00:01\n",
      "     ---------------------                    1.4/2.5 MB 5.4 MB/s eta 0:00:01\n",
      "     -------------------------                1.6/2.5 MB 5.1 MB/s eta 0:00:01\n",
      "     -----------------------------            1.8/2.5 MB 5.3 MB/s eta 0:00:01\n",
      "     --------------------------------         2.0/2.5 MB 5.2 MB/s eta 0:00:01\n",
      "     ------------------------------------     2.3/2.5 MB 5.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 MB 5.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 2.5/2.5 MB 5.2 MB/s eta 0:00:00\n",
      "Installing collected packages: pillow\n",
      "Successfully installed pillow-9.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2611624a-a953-488b-bd8e-bbb9bf22f054",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing labriries\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "492315c3-5ce6-4282-aa21-8d9eba96f376",
   "metadata": {},
   "outputs": [],
   "source": [
    "#disable the use of OpenCL in OpenCV\n",
    "cv2.ocl.setUseOpenCL(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835fc2f4-4f64-451d-87b2-6b275e8d9500",
   "metadata": {},
   "source": [
    "## preparing the train data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abb54112-9c50-44de-bc6b-c2237fe62690",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23769 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "#flow_from_directory isusing for a data like the one i have with diffrent file for each class\n",
    "train_generator = ImageDataGenerator(rescale=1./255,rotation_range=20,zoom_range=0.1,width_shift_range=0.1,height_shift_range=0.1, validation_split=0.2).flow_from_directory(\n",
    "        'data2/train',\n",
    "        target_size=(48, 48),\n",
    "        batch_size=64,\n",
    "        color_mode=\"grayscale\",\n",
    "        class_mode='categorical',subset='training')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7726a2c3-7401-4aac-ac3c-24141453d5d4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## preparing the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e60dd89b-ffa2-48b4-a059-93663bc7f383",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5941 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "val_generator = ImageDataGenerator(rescale=1./255,rotation_range=20,zoom_range=0.1,width_shift_range=0.1,height_shift_range=0.1,validation_split=0.2).flow_from_directory(\n",
    "        'data2/train',\n",
    "        target_size=(48, 48),\n",
    "        batch_size=64,\n",
    "        color_mode=\"grayscale\",\n",
    "        class_mode='categorical',subset='validation')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20b2bcc4-c3f8-48d3-a143-dc18ef591edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    min_delta=0.00005,\n",
    "    patience=10,\n",
    "    verbose=1,\n",
    "    restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b515f69a-1292-4f80-b9c3-a8113300bae9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## building the model :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6700428c-6704-4d77-b0f7-aee6eb0e91b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "my_mental_health = Sequential([#features extraction phase\n",
    "layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(48, 48, 1)),#conv2D convolution over images/input with 1 color(greyscale)\n",
    "layers.Conv2D(64, kernel_size=(3, 3), activation='relu'),#relu is activation function that turn the negative to zero\n",
    "layers.MaxPooling2D(pool_size=(2, 2)),#maxpooling2d condensing the data (take  the max from the convolution map) to reduice the size\n",
    "layers.Dropout(0.25),#protect from overfitting\n",
    "layers.Conv2D(128, kernel_size=(3, 3), activation='relu'),\n",
    "layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "layers.Conv2D(128, kernel_size=(3, 3), activation='relu'),\n",
    "layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "layers.Dropout(0.25),\n",
    "layers.Flatten(),#flatten is preparing the data to the neural network\n",
    "layers.Dense(1024, activation='relu'),#1024 number of nerons\n",
    "layers.Dropout(0.5),\n",
    "layers.Dense(7, activation='softmax')])#7units corresponding to the number of classes\n",
    "#softmax is used to normalize the output and gives probabilities of each class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "805d3c48-1947-4111-9e46-ebf03d53beb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_mental_health.compile(loss='categorical_crossentropy', optimizer=Adam( learning_rate=0.0001), metrics=['accuracy'])\n",
    "#categorical_crossentropy used for multi-class classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a17f855-c59c-4ef0-be1d-29a5caad0f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 46, 46, 32)        320       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 44, 44, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 22, 22, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 22, 22, 64)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 20, 20, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 10, 10, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 8, 8, 128)         147584    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 4, 4, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 4, 4, 128)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2048)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              2098176   \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 7)                 7175      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,345,607\n",
      "Trainable params: 2,345,607\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "my_mental_health.summary()# to show the steps of the model for the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6aa379-dc79-4eb0-8a89-e38509fc819b",
   "metadata": {},
   "source": [
    "## fitting the model :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc05ee85-8ed5-48a6-abcd-f553393f560f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "371/371 [==============================] - 234s 626ms/step - loss: 1.8160 - accuracy: 0.2400 - val_loss: 1.7994 - val_accuracy: 0.2626\n",
      "Epoch 2/100\n",
      "371/371 [==============================] - 73s 196ms/step - loss: 1.7668 - accuracy: 0.2681 - val_loss: 1.7511 - val_accuracy: 0.2879\n",
      "Epoch 3/100\n",
      "371/371 [==============================] - 72s 194ms/step - loss: 1.7281 - accuracy: 0.3003 - val_loss: 1.7005 - val_accuracy: 0.3077\n",
      "Epoch 4/100\n",
      "371/371 [==============================] - 71s 190ms/step - loss: 1.6766 - accuracy: 0.3317 - val_loss: 1.6502 - val_accuracy: 0.3516\n",
      "Epoch 5/100\n",
      "371/371 [==============================] - 74s 199ms/step - loss: 1.6298 - accuracy: 0.3574 - val_loss: 1.6047 - val_accuracy: 0.3725\n",
      "Epoch 6/100\n",
      "371/371 [==============================] - 78s 211ms/step - loss: 1.5892 - accuracy: 0.3782 - val_loss: 1.5642 - val_accuracy: 0.3843\n",
      "Epoch 7/100\n",
      "371/371 [==============================] - 76s 205ms/step - loss: 1.5508 - accuracy: 0.3995 - val_loss: 1.5420 - val_accuracy: 0.3942\n",
      "Epoch 8/100\n",
      "371/371 [==============================] - 74s 200ms/step - loss: 1.5189 - accuracy: 0.4126 - val_loss: 1.4804 - val_accuracy: 0.4283\n",
      "Epoch 9/100\n",
      "371/371 [==============================] - 76s 203ms/step - loss: 1.4829 - accuracy: 0.4284 - val_loss: 1.4403 - val_accuracy: 0.4462\n",
      "Epoch 10/100\n",
      "371/371 [==============================] - 89s 240ms/step - loss: 1.4486 - accuracy: 0.4444 - val_loss: 1.4280 - val_accuracy: 0.4497\n",
      "Epoch 11/100\n",
      "371/371 [==============================] - 78s 210ms/step - loss: 1.4248 - accuracy: 0.4552 - val_loss: 1.4046 - val_accuracy: 0.4545\n",
      "Epoch 12/100\n",
      "371/371 [==============================] - 80s 216ms/step - loss: 1.3976 - accuracy: 0.4656 - val_loss: 1.3618 - val_accuracy: 0.4859\n",
      "Epoch 13/100\n",
      "371/371 [==============================] - 79s 212ms/step - loss: 1.3816 - accuracy: 0.4732 - val_loss: 1.3811 - val_accuracy: 0.4762\n",
      "Epoch 14/100\n",
      "371/371 [==============================] - 74s 198ms/step - loss: 1.3607 - accuracy: 0.4855 - val_loss: 1.3410 - val_accuracy: 0.4888\n",
      "Epoch 15/100\n",
      "371/371 [==============================] - 75s 202ms/step - loss: 1.3382 - accuracy: 0.4904 - val_loss: 1.3315 - val_accuracy: 0.4910\n",
      "Epoch 16/100\n",
      "371/371 [==============================] - 72s 193ms/step - loss: 1.3209 - accuracy: 0.4957 - val_loss: 1.3074 - val_accuracy: 0.5017\n",
      "Epoch 17/100\n",
      "371/371 [==============================] - 72s 194ms/step - loss: 1.3048 - accuracy: 0.5044 - val_loss: 1.2886 - val_accuracy: 0.5110\n",
      "Epoch 18/100\n",
      "371/371 [==============================] - 73s 196ms/step - loss: 1.2962 - accuracy: 0.5097 - val_loss: 1.2838 - val_accuracy: 0.5141\n",
      "Epoch 19/100\n",
      "371/371 [==============================] - 73s 196ms/step - loss: 1.2864 - accuracy: 0.5111 - val_loss: 1.2691 - val_accuracy: 0.5189\n",
      "Epoch 20/100\n",
      "371/371 [==============================] - 73s 196ms/step - loss: 1.2684 - accuracy: 0.5190 - val_loss: 1.2683 - val_accuracy: 0.5168\n",
      "Epoch 21/100\n",
      "371/371 [==============================] - 73s 196ms/step - loss: 1.2612 - accuracy: 0.5231 - val_loss: 1.2548 - val_accuracy: 0.5251\n",
      "Epoch 22/100\n",
      "371/371 [==============================] - 73s 195ms/step - loss: 1.2495 - accuracy: 0.5291 - val_loss: 1.2438 - val_accuracy: 0.5265\n",
      "Epoch 23/100\n",
      "371/371 [==============================] - 73s 197ms/step - loss: 1.2426 - accuracy: 0.5344 - val_loss: 1.2408 - val_accuracy: 0.5296\n",
      "Epoch 24/100\n",
      "371/371 [==============================] - 75s 201ms/step - loss: 1.2335 - accuracy: 0.5278 - val_loss: 1.2307 - val_accuracy: 0.5340\n",
      "Epoch 25/100\n",
      "371/371 [==============================] - 73s 196ms/step - loss: 1.2249 - accuracy: 0.5357 - val_loss: 1.2190 - val_accuracy: 0.5387\n",
      "Epoch 26/100\n",
      "371/371 [==============================] - 72s 193ms/step - loss: 1.2100 - accuracy: 0.5458 - val_loss: 1.2075 - val_accuracy: 0.5389\n",
      "Epoch 27/100\n",
      "371/371 [==============================] - 72s 195ms/step - loss: 1.2091 - accuracy: 0.5405 - val_loss: 1.2184 - val_accuracy: 0.5345\n",
      "Epoch 28/100\n",
      "371/371 [==============================] - 73s 196ms/step - loss: 1.2030 - accuracy: 0.5451 - val_loss: 1.1995 - val_accuracy: 0.5484\n",
      "Epoch 29/100\n",
      "371/371 [==============================] - 72s 194ms/step - loss: 1.1883 - accuracy: 0.5524 - val_loss: 1.2185 - val_accuracy: 0.5447\n",
      "Epoch 30/100\n",
      "371/371 [==============================] - 73s 196ms/step - loss: 1.1859 - accuracy: 0.5553 - val_loss: 1.2022 - val_accuracy: 0.5521\n",
      "Epoch 31/100\n",
      "371/371 [==============================] - 74s 199ms/step - loss: 1.1753 - accuracy: 0.5561 - val_loss: 1.1852 - val_accuracy: 0.5530\n",
      "Epoch 32/100\n",
      "371/371 [==============================] - 73s 197ms/step - loss: 1.1676 - accuracy: 0.5638 - val_loss: 1.1940 - val_accuracy: 0.5447\n",
      "Epoch 33/100\n",
      "371/371 [==============================] - 73s 198ms/step - loss: 1.1645 - accuracy: 0.5603 - val_loss: 1.1888 - val_accuracy: 0.5521\n",
      "Epoch 34/100\n",
      "371/371 [==============================] - 78s 210ms/step - loss: 1.1568 - accuracy: 0.5609 - val_loss: 1.1740 - val_accuracy: 0.5560\n",
      "Epoch 35/100\n",
      "371/371 [==============================] - 132s 355ms/step - loss: 1.1522 - accuracy: 0.5628 - val_loss: 1.1619 - val_accuracy: 0.5591\n",
      "Epoch 36/100\n",
      "371/371 [==============================] - 144s 388ms/step - loss: 1.1475 - accuracy: 0.5663 - val_loss: 1.1641 - val_accuracy: 0.5603\n",
      "Epoch 37/100\n",
      "371/371 [==============================] - 74s 199ms/step - loss: 1.1435 - accuracy: 0.5700 - val_loss: 1.1555 - val_accuracy: 0.5581\n",
      "Epoch 38/100\n",
      "371/371 [==============================] - 78s 210ms/step - loss: 1.1394 - accuracy: 0.5696 - val_loss: 1.1625 - val_accuracy: 0.5588\n",
      "Epoch 39/100\n",
      "371/371 [==============================] - 76s 206ms/step - loss: 1.1303 - accuracy: 0.5736 - val_loss: 1.1489 - val_accuracy: 0.5661\n",
      "Epoch 40/100\n",
      "371/371 [==============================] - 95s 255ms/step - loss: 1.1238 - accuracy: 0.5791 - val_loss: 1.1356 - val_accuracy: 0.5656\n",
      "Epoch 41/100\n",
      "371/371 [==============================] - 87s 234ms/step - loss: 1.1174 - accuracy: 0.5788 - val_loss: 1.1490 - val_accuracy: 0.5683\n",
      "Epoch 42/100\n",
      "371/371 [==============================] - 78s 210ms/step - loss: 1.1160 - accuracy: 0.5774 - val_loss: 1.1472 - val_accuracy: 0.5661\n",
      "Epoch 43/100\n",
      "371/371 [==============================] - 87s 234ms/step - loss: 1.1111 - accuracy: 0.5842 - val_loss: 1.1368 - val_accuracy: 0.5679\n",
      "Epoch 44/100\n",
      "371/371 [==============================] - 87s 233ms/step - loss: 1.0991 - accuracy: 0.5873 - val_loss: 1.1511 - val_accuracy: 0.5671\n",
      "Epoch 45/100\n",
      "371/371 [==============================] - 76s 204ms/step - loss: 1.1001 - accuracy: 0.5864 - val_loss: 1.1292 - val_accuracy: 0.5727\n",
      "Epoch 46/100\n",
      "371/371 [==============================] - 73s 196ms/step - loss: 1.0942 - accuracy: 0.5912 - val_loss: 1.1318 - val_accuracy: 0.5681\n",
      "Epoch 47/100\n",
      "371/371 [==============================] - 72s 194ms/step - loss: 1.0907 - accuracy: 0.5874 - val_loss: 1.1173 - val_accuracy: 0.5756\n",
      "Epoch 48/100\n",
      "371/371 [==============================] - 77s 206ms/step - loss: 1.0896 - accuracy: 0.5883 - val_loss: 1.1201 - val_accuracy: 0.5808\n",
      "Epoch 49/100\n",
      "371/371 [==============================] - 73s 197ms/step - loss: 1.0800 - accuracy: 0.5973 - val_loss: 1.1141 - val_accuracy: 0.5814\n",
      "Epoch 50/100\n",
      "371/371 [==============================] - 73s 196ms/step - loss: 1.0743 - accuracy: 0.5957 - val_loss: 1.1187 - val_accuracy: 0.5812\n",
      "Epoch 51/100\n",
      "371/371 [==============================] - 73s 198ms/step - loss: 1.0732 - accuracy: 0.5985 - val_loss: 1.1318 - val_accuracy: 0.5727\n",
      "Epoch 52/100\n",
      "371/371 [==============================] - 73s 196ms/step - loss: 1.0604 - accuracy: 0.6022 - val_loss: 1.0951 - val_accuracy: 0.5810\n",
      "Epoch 53/100\n",
      "371/371 [==============================] - 75s 201ms/step - loss: 1.0646 - accuracy: 0.5984 - val_loss: 1.1049 - val_accuracy: 0.5810\n",
      "Epoch 54/100\n",
      "371/371 [==============================] - 83s 224ms/step - loss: 1.0528 - accuracy: 0.6062 - val_loss: 1.1051 - val_accuracy: 0.5881\n",
      "Epoch 55/100\n",
      "371/371 [==============================] - 74s 199ms/step - loss: 1.0530 - accuracy: 0.6053 - val_loss: 1.1057 - val_accuracy: 0.5881\n",
      "Epoch 56/100\n",
      "371/371 [==============================] - 73s 196ms/step - loss: 1.0506 - accuracy: 0.6042 - val_loss: 1.0929 - val_accuracy: 0.5856\n",
      "Epoch 57/100\n",
      "371/371 [==============================] - 73s 197ms/step - loss: 1.0451 - accuracy: 0.6060 - val_loss: 1.1061 - val_accuracy: 0.5851\n",
      "Epoch 58/100\n",
      "371/371 [==============================] - 72s 194ms/step - loss: 1.0435 - accuracy: 0.6097 - val_loss: 1.0938 - val_accuracy: 0.5871\n",
      "Epoch 59/100\n",
      "371/371 [==============================] - 74s 199ms/step - loss: 1.0357 - accuracy: 0.6125 - val_loss: 1.0926 - val_accuracy: 0.5907\n",
      "Epoch 60/100\n",
      "371/371 [==============================] - 72s 193ms/step - loss: 1.0360 - accuracy: 0.6127 - val_loss: 1.0948 - val_accuracy: 0.5926\n",
      "Epoch 61/100\n",
      "371/371 [==============================] - 73s 197ms/step - loss: 1.0274 - accuracy: 0.6135 - val_loss: 1.0958 - val_accuracy: 0.5897\n",
      "Epoch 62/100\n",
      "371/371 [==============================] - 72s 194ms/step - loss: 1.0252 - accuracy: 0.6148 - val_loss: 1.0923 - val_accuracy: 0.5827\n",
      "Epoch 63/100\n",
      "371/371 [==============================] - 72s 195ms/step - loss: 1.0257 - accuracy: 0.6132 - val_loss: 1.0821 - val_accuracy: 0.5858\n",
      "Epoch 64/100\n",
      "371/371 [==============================] - 73s 197ms/step - loss: 1.0189 - accuracy: 0.6202 - val_loss: 1.0889 - val_accuracy: 0.5917\n",
      "Epoch 65/100\n",
      "371/371 [==============================] - 73s 196ms/step - loss: 1.0176 - accuracy: 0.6201 - val_loss: 1.0832 - val_accuracy: 0.5931\n",
      "Epoch 66/100\n",
      "371/371 [==============================] - 74s 198ms/step - loss: 1.0085 - accuracy: 0.6223 - val_loss: 1.1002 - val_accuracy: 0.5834\n",
      "Epoch 67/100\n",
      "371/371 [==============================] - 72s 194ms/step - loss: 1.0026 - accuracy: 0.6260 - val_loss: 1.0860 - val_accuracy: 0.5895\n",
      "Epoch 68/100\n",
      "371/371 [==============================] - 71s 192ms/step - loss: 1.0067 - accuracy: 0.6229 - val_loss: 1.0740 - val_accuracy: 0.5975\n",
      "Epoch 69/100\n",
      "371/371 [==============================] - 73s 197ms/step - loss: 1.0019 - accuracy: 0.6215 - val_loss: 1.0695 - val_accuracy: 0.5997\n",
      "Epoch 70/100\n",
      "371/371 [==============================] - 73s 196ms/step - loss: 0.9938 - accuracy: 0.6281 - val_loss: 1.0641 - val_accuracy: 0.5954\n",
      "Epoch 71/100\n",
      "371/371 [==============================] - 73s 196ms/step - loss: 0.9960 - accuracy: 0.6271 - val_loss: 1.0711 - val_accuracy: 0.5949\n",
      "Epoch 72/100\n",
      "371/371 [==============================] - 74s 200ms/step - loss: 0.9935 - accuracy: 0.6280 - val_loss: 1.0707 - val_accuracy: 0.5951\n",
      "Epoch 73/100\n",
      "371/371 [==============================] - 80s 214ms/step - loss: 0.9916 - accuracy: 0.6314 - val_loss: 1.0661 - val_accuracy: 0.6036\n",
      "Epoch 74/100\n",
      "371/371 [==============================] - 78s 210ms/step - loss: 0.9929 - accuracy: 0.6285 - val_loss: 1.0771 - val_accuracy: 0.5956\n",
      "Epoch 75/100\n",
      "371/371 [==============================] - 80s 215ms/step - loss: 0.9798 - accuracy: 0.6348 - val_loss: 1.0635 - val_accuracy: 0.6039\n",
      "Epoch 76/100\n",
      "371/371 [==============================] - 75s 201ms/step - loss: 0.9735 - accuracy: 0.6352 - val_loss: 1.0785 - val_accuracy: 0.5977\n",
      "Epoch 77/100\n",
      "371/371 [==============================] - 73s 197ms/step - loss: 0.9659 - accuracy: 0.6397 - val_loss: 1.0551 - val_accuracy: 0.6044\n",
      "Epoch 78/100\n",
      "371/371 [==============================] - 71s 192ms/step - loss: 0.9605 - accuracy: 0.6412 - val_loss: 1.0735 - val_accuracy: 0.5968\n",
      "Epoch 79/100\n",
      "371/371 [==============================] - 73s 197ms/step - loss: 0.9608 - accuracy: 0.6413 - val_loss: 1.0552 - val_accuracy: 0.6038\n",
      "Epoch 80/100\n",
      "371/371 [==============================] - 72s 194ms/step - loss: 0.9645 - accuracy: 0.6405 - val_loss: 1.0571 - val_accuracy: 0.6061\n",
      "Epoch 81/100\n",
      "371/371 [==============================] - 73s 195ms/step - loss: 0.9522 - accuracy: 0.6444 - val_loss: 1.0632 - val_accuracy: 0.6029\n",
      "Epoch 82/100\n",
      "371/371 [==============================] - 72s 194ms/step - loss: 0.9564 - accuracy: 0.6414 - val_loss: 1.0610 - val_accuracy: 0.6031\n",
      "Epoch 83/100\n",
      "371/371 [==============================] - 74s 199ms/step - loss: 0.9544 - accuracy: 0.6429 - val_loss: 1.0560 - val_accuracy: 0.6068\n",
      "Epoch 84/100\n",
      "371/371 [==============================] - 72s 194ms/step - loss: 0.9442 - accuracy: 0.6494 - val_loss: 1.0486 - val_accuracy: 0.6102\n",
      "Epoch 85/100\n",
      "371/371 [==============================] - 74s 198ms/step - loss: 0.9450 - accuracy: 0.6472 - val_loss: 1.0501 - val_accuracy: 0.6124\n",
      "Epoch 86/100\n",
      "371/371 [==============================] - 73s 197ms/step - loss: 0.9474 - accuracy: 0.6438 - val_loss: 1.0637 - val_accuracy: 0.5948\n",
      "Epoch 87/100\n",
      "371/371 [==============================] - 72s 194ms/step - loss: 0.9378 - accuracy: 0.6504 - val_loss: 1.0505 - val_accuracy: 0.6050\n",
      "Epoch 88/100\n",
      "371/371 [==============================] - 74s 200ms/step - loss: 0.9365 - accuracy: 0.6477 - val_loss: 1.0499 - val_accuracy: 0.6043\n",
      "Epoch 89/100\n",
      "371/371 [==============================] - 74s 200ms/step - loss: 0.9354 - accuracy: 0.6510 - val_loss: 1.0578 - val_accuracy: 0.5985\n",
      "Epoch 90/100\n",
      "371/371 [==============================] - 86s 230ms/step - loss: 0.9336 - accuracy: 0.6503 - val_loss: 1.0489 - val_accuracy: 0.6029\n",
      "Epoch 91/100\n",
      "371/371 [==============================] - 76s 205ms/step - loss: 0.9297 - accuracy: 0.6511 - val_loss: 1.0581 - val_accuracy: 0.6046\n",
      "Epoch 92/100\n",
      "371/371 [==============================] - 78s 210ms/step - loss: 0.9222 - accuracy: 0.6579 - val_loss: 1.0460 - val_accuracy: 0.6044\n",
      "Epoch 93/100\n",
      "371/371 [==============================] - 77s 207ms/step - loss: 0.9258 - accuracy: 0.6524 - val_loss: 1.0407 - val_accuracy: 0.6072\n",
      "Epoch 94/100\n",
      "371/371 [==============================] - 78s 209ms/step - loss: 0.9193 - accuracy: 0.6586 - val_loss: 1.0480 - val_accuracy: 0.6097\n",
      "Epoch 95/100\n",
      "371/371 [==============================] - ETA: 0s - loss: 0.9149 - accuracy: 0.6604Restoring model weights from the end of the best epoch: 85.\n",
      "371/371 [==============================] - 77s 208ms/step - loss: 0.9149 - accuracy: 0.6604 - val_loss: 1.0525 - val_accuracy: 0.6106\n",
      "Epoch 95: early stopping\n"
     ]
    }
   ],
   "source": [
    "my_mental_health_info = my_mental_health.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=train_generator.samples // 64,\n",
    "        epochs=100,\n",
    "        validation_data=val_generator,\n",
    "        validation_steps=val_generator.samples // 64,callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b5f7c3-c2a4-43c6-b65f-828fe463d6c4",
   "metadata": {},
   "source": [
    "\n",
    "## make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0eff3bef-9632-4136-95af-51179d97eba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7178 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator = ImageDataGenerator(rescale=1./255,rotation_range=20,zoom_range=0.1,width_shift_range=0.1,height_shift_range=0.1).flow_from_directory(\n",
    "        'data2/test',\n",
    "        target_size=(48, 48),\n",
    "        batch_size=64,\n",
    "        color_mode=\"grayscale\",\n",
    "        class_mode='categorical', shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1b8b2734-6d0a-4c03-a4d8-f3f7352a8973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 11s 94ms/step - loss: 1.0413 - accuracy: 0.6150\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = my_mental_health.evaluate(test_generator, steps= test_generator.samples// 64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753ba163-0723-4425-b886-8c987bef8a2c",
   "metadata": {},
   "source": [
    "## check accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8e29ff86-2f9f-46b2-8beb-17501be1067d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.0413\n",
      "Test Accuracy: 0.6150\n"
     ]
    }
   ],
   "source": [
    "print(f'Test Loss: {test_loss:.4f}')\n",
    "print(f'Test Accuracy: {test_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6dacbbc-0da6-4f8d-b2b5-dace900369e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 47s 420ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = my_mental_health.predict(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a130a1a1-a7ca-4817-9863-b824e34f33e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6060183895235441\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "predicted_labels = np.argmax(predictions, axis=1)  # Get the index of the predicted class with highest probability\n",
    "true_labels = test_generator.classes  # Get the true labels of the test samples\n",
    "\n",
    "accuracy = np.mean(predicted_labels == true_labels)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5db4279-3ba8-4b1b-ab89-3dbb41ae62fc",
   "metadata": {},
   "source": [
    "## save the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba440398-8a6c-4879-9a9c-4eba482471fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_mental_health.save('my_mental_health2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8868fb0c-a233-4333-8fb8-148c3e0ea187",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
